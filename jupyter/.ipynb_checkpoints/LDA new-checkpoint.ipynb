{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "from gensim import corpora, models, parsing\n",
    "from gensim.models import LdaModel\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pyLDAvis.gensim\n",
    "import itertools\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet', quiet=True)\n",
    "np.random.seed(2018)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_id_from_series(series):\n",
    "        return int(series.index.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training LDA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6     \\\n",
      "id                                                                             \n",
      "6       1.000000  0.000000  0.002988  0.004544  0.000000  0.000000  0.008515   \n",
      "4       0.000000  1.000000  0.003184  0.065896  0.000000  0.000000  0.085236   \n",
      "1       0.002988  0.003184  1.000000  0.000000  0.000000  0.006623  0.005563   \n",
      "10      0.004544  0.065896  0.000000  1.000000  0.000000  0.004847  0.010860   \n",
      "9       0.000000  0.000000  0.000000  0.000000  1.000000  0.106605  0.000000   \n",
      "2       0.000000  0.000000  0.006623  0.004847  0.106605  1.000000  0.010237   \n",
      "7       0.008515  0.085236  0.005563  0.010860  0.000000  0.010237  1.000000   \n",
      "5       0.028263  0.007246  0.005911  0.000000  0.032243  0.000000  0.023146   \n",
      "3       0.040046  0.023752  0.000000  0.003382  0.000000  0.005555  0.008085   \n",
      "8       0.000000  0.033567  0.005793  0.022331  0.000000  0.000000  0.009994   \n",
      "11      0.000000  0.000000  0.000000  0.000000  0.142882  0.000000  0.004969   \n",
      "157     0.007421  0.000000  0.008020  0.010067  0.049040  0.000000  0.000000   \n",
      "17      0.009594  0.005522  0.006140  0.000000  0.000000  0.000000  0.047574   \n",
      "25      0.011739  0.047576  0.015861  0.000000  0.000000  0.000000  0.005758   \n",
      "77      0.000000  0.058515  0.018864  0.000000  0.000000  0.000000  0.007422   \n",
      "78      0.000000  0.000000  0.000000  0.019739  0.000000  0.045371  0.009567   \n",
      "42      0.025472  0.053786  0.008666  0.000000  0.066812  0.000000  0.000000   \n",
      "13      0.009600  0.030761  0.009959  0.018880  0.034453  0.016969  0.000000   \n",
      "156     0.000000  0.036099  0.000000  0.000000  0.000000  0.000000  0.005910   \n",
      "155     0.004938  0.024197  0.002706  0.006699  0.000000  0.006675  0.003785   \n",
      "154     0.003567  0.029184  0.002410  0.000000  0.000000  0.000000  0.023305   \n",
      "74      0.004382  0.032330  0.002961  0.000000  0.000000  0.000000  0.005538   \n",
      "153     0.005724  0.029265  0.009291  0.003727  0.000000  0.007652  0.007097   \n",
      "152     0.000000  0.000000  0.000000  0.000000  0.000000  0.023396  0.000000   \n",
      "151     0.017925  0.008986  0.006493  0.029418  0.000000  0.016150  0.011202   \n",
      "150     0.000000  0.027462  0.020293  0.017827  0.000000  0.000000  0.007733   \n",
      "24      0.010032  0.014741  0.002434  0.004975  0.024643  0.000000  0.018376   \n",
      "40      0.021284  0.037687  0.007912  0.021076  0.000000  0.000000  0.000000   \n",
      "73      0.023272  0.086820  0.002428  0.000000  0.000000  0.000000  0.026056   \n",
      "41      0.000000  0.000000  0.004837  0.000000  0.000000  0.039153  0.000000   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "108979  0.020912  0.000000  0.000000  0.025635  0.000000  0.000000  0.000000   \n",
      "105954  0.000000  0.009870  0.000000  0.000000  0.000000  0.008576  0.028941   \n",
      "121113  0.000000  0.009509  0.021773  0.000000  0.000000  0.000000  0.000000   \n",
      "119068  0.039999  0.037479  0.003915  0.000000  0.022988  0.052299  0.020057   \n",
      "143859  0.000000  0.062706  0.010760  0.000000  0.000000  0.000000  0.015304   \n",
      "141956  0.000000  0.013444  0.030477  0.033315  0.064749  0.000000  0.016759   \n",
      "108873  0.000000  0.000000  0.000000  0.000000  0.042221  0.000000  0.000000   \n",
      "134025  0.000000  0.047765  0.003752  0.025930  0.000000  0.008538  0.026463   \n",
      "114464  0.000000  0.070978  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "110781  0.012425  0.006541  0.007433  0.017527  0.000000  0.011757  0.017981   \n",
      "109578  0.000000  0.024913  0.000000  0.012593  0.068422  0.009303  0.061669   \n",
      "158238  0.023008  0.005046  0.010083  0.075217  0.000000  0.008911  0.006290   \n",
      "132952  0.019798  0.035216  0.000000  0.006060  0.046658  0.012688  0.056784   \n",
      "115680  0.000000  0.000000  0.000000  0.020997  0.000000  0.009438  0.005352   \n",
      "141886  0.002723  0.008403  0.001839  0.000000  0.018692  0.032882  0.007705   \n",
      "104129  0.007941  0.035526  0.006214  0.021029  0.031052  0.000000  0.022143   \n",
      "116799  0.000000  0.061523  0.000000  0.000000  0.075751  0.000000  0.000000   \n",
      "105755  0.034329  0.000000  0.008593  0.000000  0.000000  0.000000  0.027269   \n",
      "160271  0.003283  0.011805  0.017673  0.026590  0.009038  0.010483  0.001437   \n",
      "136800  0.022558  0.000000  0.012337  0.009116  0.000000  0.000000  0.000000   \n",
      "109249  0.000000  0.023854  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "138696  0.000000  0.041263  0.000000  0.000000  0.000000  0.000000  0.036277   \n",
      "105213  0.013877  0.081709  0.004862  0.000000  0.000000  0.000000  0.042851   \n",
      "140743  0.036417  0.021119  0.020938  0.035234  0.000000  0.000000  0.007477   \n",
      "109317  0.000000  0.089450  0.000000  0.000000  0.000000  0.000000  0.010825   \n",
      "138546  0.002762  0.008050  0.001866  0.000000  0.000000  0.000000  0.033157   \n",
      "138204  0.000000  0.013585  0.114992  0.000000  0.025291  0.058621  0.000000   \n",
      "117529  0.000000  0.007169  0.006560  0.027221  0.000000  0.010681  0.040307   \n",
      "107555  0.000000  0.045680  0.006473  0.000000  0.000000  0.000000  0.009491   \n",
      "140523  0.000000  0.000000  0.003978  0.000000  0.000000  0.010643  0.000000   \n",
      "\n",
      "            7         8         9       ...         9091      9092      9093  \\\n",
      "id                                      ...                                    \n",
      "6       0.028263  0.040046  0.000000    ...     0.000000  0.000000  0.013877   \n",
      "4       0.007246  0.023752  0.033567    ...     0.023854  0.041263  0.081709   \n",
      "1       0.005911  0.000000  0.005793    ...     0.000000  0.000000  0.004862   \n",
      "10      0.000000  0.003382  0.022331    ...     0.000000  0.000000  0.000000   \n",
      "9       0.032243  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "2       0.000000  0.005555  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "7       0.023146  0.008085  0.009994    ...     0.000000  0.036277  0.042851   \n",
      "5       1.000000  0.021143  0.023816    ...     0.024492  0.000000  0.023887   \n",
      "3       0.021143  1.000000  0.010426    ...     0.000000  0.000000  0.013409   \n",
      "8       0.023816  0.010426  1.000000    ...     0.008864  0.021350  0.006789   \n",
      "11      0.035391  0.000000  0.003792    ...     0.005641  0.007367  0.007897   \n",
      "157     0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "17      0.027581  0.022990  0.015462    ...     0.000000  0.000000  0.013223   \n",
      "25      0.026132  0.077450  0.000000    ...     0.030236  0.000000  0.015645   \n",
      "77      0.000000  0.009131  0.000000    ...     0.041094  0.000000  0.020166   \n",
      "78      0.011635  0.023038  0.000000    ...     0.000000  0.000000  0.015909   \n",
      "42      0.059467  0.000000  0.000000    ...     0.021321  0.000000  0.000000   \n",
      "13      0.000000  0.000000  0.000000    ...     0.036072  0.000000  0.000000   \n",
      "156     0.000000  0.095158  0.000000    ...     0.009704  0.000000  0.009330   \n",
      "155     0.023790  0.024332  0.045963    ...     0.000000  0.000000  0.000000   \n",
      "154     0.000000  0.019423  0.006691    ...     0.009954  0.013000  0.022601   \n",
      "74      0.000000  0.012208  0.008220    ...     0.012228  0.015970  0.007524   \n",
      "153     0.003080  0.024985  0.003408    ...     0.000000  0.000000  0.006203   \n",
      "152     0.065804  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "151     0.026692  0.011685  0.051134    ...     0.000000  0.052025  0.007609   \n",
      "150     0.000000  0.010518  0.000000    ...     0.000000  0.000000  0.035320   \n",
      "24      0.005540  0.016776  0.016526    ...     0.025014  0.000000  0.034923   \n",
      "40      0.005955  0.000000  0.000000    ...     0.146313  0.000000  0.030120   \n",
      "73      0.005526  0.036184  0.006115    ...     0.000000  0.044391  0.006171   \n",
      "41      0.000000  0.023367  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "...          ...       ...       ...    ...          ...       ...       ...   \n",
      "108979  0.061309  0.032513  0.054678    ...     0.019506  0.000000  0.000000   \n",
      "105954  0.020339  0.008918  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "121113  0.000000  0.021833  0.000000    ...     0.000000  0.020767  0.000000   \n",
      "119068  0.017816  0.048899  0.024576    ...     0.000000  0.015572  0.034613   \n",
      "143859  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "141956  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "108873  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "134025  0.008539  0.029931  0.025472    ...     0.000000  0.000000  0.030144   \n",
      "114464  0.000000  0.000000  0.035273    ...     0.000000  0.000000  0.000000   \n",
      "110781  0.004960  0.017385  0.010351    ...     0.017553  0.009446  0.037909   \n",
      "109578  0.022950  0.030805  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "158238  0.004280  0.005473  0.003685    ...     0.012527  0.129598  0.000000   \n",
      "132952  0.000000  0.000000  0.004143    ...     0.000000  0.008049  0.000000   \n",
      "115680  0.021733  0.019566  0.030212    ...     0.017820  0.011975  0.000000   \n",
      "141886  0.000000  0.005542  0.000000    ...     0.000000  0.012662  0.000000   \n",
      "104129  0.000000  0.038997  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "116799  0.017127  0.000000  0.042293    ...     0.000000  0.000000  0.000000   \n",
      "105755  0.046788  0.012259  0.000000    ...     0.000000  0.000000  0.020890   \n",
      "160271  0.004822  0.022224  0.006554    ...     0.022809  0.061262  0.000000   \n",
      "136800  0.020990  0.019246  0.007712    ...     0.025776  0.006460  0.000000   \n",
      "109249  0.024492  0.000000  0.008864    ...     1.000000  0.017222  0.000000   \n",
      "138696  0.000000  0.000000  0.021350    ...     0.017222  1.000000  0.000000   \n",
      "105213  0.023887  0.013409  0.006789    ...     0.000000  0.000000  1.000000   \n",
      "140743  0.021470  0.000000  0.012005    ...     0.012020  0.009101  0.010159   \n",
      "109317  0.030002  0.013318  0.020168    ...     0.000000  0.039183  0.029414   \n",
      "138546  0.000000  0.000000  0.000000    ...     0.010997  0.000000  0.004742   \n",
      "138204  0.000000  0.000000  0.000000    ...     0.016958  0.000000  0.000000   \n",
      "117529  0.000000  0.007452  0.000000    ...     0.000000  0.000000  0.021299   \n",
      "107555  0.086626  0.030359  0.005237    ...     0.065333  0.010174  0.048621   \n",
      "140523  0.000000  0.007390  0.000000    ...     0.018792  0.000000  0.000000   \n",
      "\n",
      "            9094      9095      9096      9097      9098      9099      9100  \n",
      "id                                                                            \n",
      "6       0.036417  0.000000  0.002762  0.000000  0.000000  0.000000  0.000000  \n",
      "4       0.021119  0.089450  0.008050  0.013585  0.007169  0.045680  0.000000  \n",
      "1       0.020938  0.000000  0.001866  0.114992  0.006560  0.006473  0.003978  \n",
      "10      0.035234  0.000000  0.000000  0.000000  0.027221  0.000000  0.000000  \n",
      "9       0.000000  0.000000  0.000000  0.025291  0.000000  0.000000  0.000000  \n",
      "2       0.000000  0.000000  0.000000  0.058621  0.010681  0.000000  0.010643  \n",
      "7       0.007477  0.010825  0.033157  0.000000  0.040307  0.009491  0.000000  \n",
      "5       0.021470  0.030002  0.000000  0.000000  0.000000  0.086626  0.000000  \n",
      "3       0.000000  0.013318  0.000000  0.000000  0.007452  0.030359  0.007390  \n",
      "8       0.012005  0.020168  0.000000  0.000000  0.000000  0.005237  0.000000  \n",
      "11      0.012615  0.019282  0.032249  0.000000  0.012042  0.017223  0.000000  \n",
      "157     0.035453  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "17      0.010084  0.021212  0.009420  0.043874  0.000000  0.036487  0.000000  \n",
      "25      0.000000  0.081262  0.044611  0.033961  0.000000  0.036899  0.006266  \n",
      "77      0.031275  0.020029  0.000000  0.000000  0.022706  0.017561  0.000000  \n",
      "78      0.000000  0.008696  0.000000  0.000000  0.004993  0.013854  0.021338  \n",
      "42      0.018856  0.053679  0.000000  0.012143  0.000000  0.000000  0.022473  \n",
      "13      0.027474  0.000000  0.015610  0.000000  0.023446  0.042619  0.023426  \n",
      "156     0.028862  0.000000  0.013692  0.000000  0.000000  0.013841  0.000000  \n",
      "155     0.012615  0.000000  0.019231  0.013134  0.006304  0.056079  0.024074  \n",
      "154     0.011304  0.016364  0.059210  0.000000  0.000000  0.065337  0.000000  \n",
      "74      0.013886  0.000000  0.006482  0.000000  0.000000  0.007223  0.000000  \n",
      "153     0.005099  0.000000  0.018937  0.013411  0.000000  0.030826  0.008649  \n",
      "152     0.000000  0.021995  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "151     0.008205  0.000000  0.000000  0.000000  0.000000  0.013706  0.000000  \n",
      "150     0.007116  0.000000  0.029874  0.000000  0.019641  0.000000  0.017806  \n",
      "24      0.007363  0.045920  0.012464  0.000000  0.005481  0.026293  0.183155  \n",
      "40      0.030411  0.012219  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "73      0.036040  0.012455  0.005401  0.000000  0.000000  0.015232  0.000000  \n",
      "41      0.000000  0.000000  0.000000  0.074850  0.000000  0.020014  0.015739  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "108979  0.000000  0.000000  0.000000  0.000000  0.008351  0.000000  0.006569  \n",
      "105954  0.000000  0.008451  0.015871  0.000000  0.000000  0.000000  0.000000  \n",
      "121113  0.007430  0.000000  0.006937  0.000000  0.000000  0.020995  0.000000  \n",
      "119068  0.066211  0.088833  0.008820  0.033464  0.000000  0.009839  0.033536  \n",
      "143859  0.012483  0.037306  0.000000  0.000000  0.000000  0.039794  0.000000  \n",
      "141956  0.000000  0.000000  0.000000  0.052478  0.009910  0.000000  0.000000  \n",
      "108873  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "134025  0.000000  0.020468  0.000000  0.000000  0.038031  0.017945  0.044274  \n",
      "114464  0.011747  0.000000  0.010966  0.047240  0.000000  0.000000  0.000000  \n",
      "110781  0.024639  0.000000  0.074712  0.000000  0.000000  0.048434  0.024567  \n",
      "109578  0.000000  0.000000  0.021225  0.000000  0.000000  0.000000  0.000000  \n",
      "158238  0.016834  0.000000  0.000000  0.000000  0.015422  0.003238  0.011035  \n",
      "132952  0.003858  0.027897  0.004894  0.000000  0.022611  0.000000  0.006556  \n",
      "115680  0.005740  0.024712  0.037082  0.000000  0.008914  0.000000  0.015290  \n",
      "141886  0.019507  0.000000  0.014788  0.039176  0.009113  0.000000  0.000000  \n",
      "104129  0.014573  0.000000  0.000000  0.000000  0.027260  0.000000  0.000000  \n",
      "116799  0.022687  0.069122  0.008484  0.000000  0.000000  0.024981  0.032120  \n",
      "105755  0.000000  0.050402  0.030686  0.000000  0.081240  0.000000  0.000000  \n",
      "160271  0.006103  0.014676  0.044229  0.000000  0.025496  0.021524  0.007296  \n",
      "136800  0.056377  0.009262  0.017007  0.000000  0.008118  0.038181  0.010156  \n",
      "109249  0.012020  0.000000  0.010997  0.016958  0.000000  0.065333  0.018792  \n",
      "138696  0.009101  0.039183  0.000000  0.000000  0.000000  0.010174  0.000000  \n",
      "105213  0.010159  0.029414  0.004742  0.000000  0.021299  0.048621  0.000000  \n",
      "140743  1.000000  0.018780  0.015041  0.000000  0.000000  0.000000  0.024466  \n",
      "109317  0.018780  1.000000  0.011913  0.000000  0.000000  0.069375  0.000000  \n",
      "138546  0.015041  0.011913  1.000000  0.000000  0.000000  0.016006  0.005109  \n",
      "138204  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000  0.027751  \n",
      "117529  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.005027  \n",
      "107555  0.000000  0.069375  0.016006  0.000000  0.000000  1.000000  0.022855  \n",
      "140523  0.024466  0.000000  0.005109  0.027751  0.005027  0.022855  1.000000  \n",
      "\n",
      "[9101 rows x 9101 columns]\n",
      "Finished training LDA model...\n"
     ]
    }
   ],
   "source": [
    "class LDAModel:\n",
    "    def __init__(self):\n",
    "        self.no_below = 5\n",
    "        self.no_above = 0.2\n",
    "        self.num_topics = 10\n",
    "        self.num_of_iterations = 100\n",
    "        self.passes = 2\n",
    "        self.minimum_probability = 0.01\n",
    "\n",
    "    def _lemmatize_stemming(self, text):\n",
    "        return stemmer.stem(WordNetLemmatizer().lemmatize(text))\n",
    "    \n",
    "    def _preprocess(self, text):\n",
    "        unigrams = []\n",
    "        for token in gensim.utils.simple_preprocess(text):\n",
    "            if token not in parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "                unigrams.append(self._lemmatize_stemming(token))\n",
    "                \n",
    "        # bi_grams = ['_'.join(b) for b in nltk.bigrams(unigrams)]\n",
    "        # tri_grams = ['_'.join(t) for t in nltk.trigrams(unigrams)]\n",
    "        \n",
    "        return list(itertools.chain(unigrams))\n",
    "    \n",
    "    def _savePickleFile(self, fileName, data):\n",
    "        fileName = f'./{fileName}.pickle'\n",
    "        mappingFile = open(fileName, 'wb')\n",
    "        pickle.dump(data, mappingFile)\n",
    "        mappingFile.close()\n",
    "\n",
    "    def saveModel(self, lda, corpus, df):\n",
    "        # Save model output\n",
    "        lda.save('./model')\n",
    "        # Save corpus\n",
    "        self._savePickleFile('corpus', corpus)\n",
    "        self._savePickleFile('df', df)\n",
    "\n",
    "    def trainModel(self):\n",
    "        data = pd.read_json('../data/movies_data.json', orient='split')\n",
    "        documents = data['content']\n",
    "        ids = data['id']\n",
    "        processed_docs = documents.map(self._preprocess)\n",
    "\n",
    "        print('Start training LDA model...')\n",
    "        dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "        dictionary.filter_extremes(no_below = self.no_below, no_above=self.no_above)\n",
    "        corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "        \n",
    "        tf_idf = models.TfidfModel(corpus)\n",
    "        corpus_tf_idf = tf_idf[corpus]\n",
    "        \n",
    "        lda = LdaModel(\n",
    "            corpus_tf_idf,\n",
    "            num_topics=self.num_topics,\n",
    "            id2word=dictionary,\n",
    "            passes=self.passes,\n",
    "            iterations=self.num_of_iterations,\n",
    "            minimum_probability=self.minimum_probability)\n",
    "        \n",
    "        index = gensim.similarities.MatrixSimilarity(corpus_tf_idf)\n",
    "        coo = coo_matrix(index)\n",
    "        similarity_matrix = np.zeros(((len(ids)), len(ids)))\n",
    "        \n",
    "        for i,j,v in zip(coo.row, coo.col, coo.data):\n",
    "            similarity_matrix[i, j] = 1 if v > 1 else v\n",
    "            \n",
    "        df_similarity_matrix = pd.DataFrame(similarity_matrix, index=ids, columns=ids)\n",
    "        \n",
    "        # lda_display = pyLDAvis.gensim.prepare(lda, corpus_tf_idf, dictionary, sort_topics=False)\n",
    "        # pyLDAvis.show(lda_display)\n",
    "        \n",
    "        print('Finished training LDA model...')\n",
    "        \n",
    "        return lda, corpus, df_similarity_matrix\n",
    "    \n",
    "lda_model = LDAModel()\n",
    "lda, corpus, df = lda_model.trainModel()  # train a LDA model using the assgined corpora\n",
    "lda_model.saveModel(lda, corpus, df) # save model for recommendations use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender():\n",
    "    def __init__(self):\n",
    "        self.lda = LdaModel.load('./model')\n",
    "        self.corpus = self.loadPickleFile('./corpus')\n",
    "        self.docs_topics = self.loadPickleFile('./docs_topics')\n",
    "        self.num_of_recommendation = 10\n",
    "        \n",
    "    def loadPickleFile(self, fileName):\n",
    "        file = open(f'{fileName}.pickle','rb')\n",
    "        object_file = pickle.load(file)\n",
    "        return object_file\n",
    "    \n",
    "    def recommend(self, movie_id):\n",
    "        data = pd.read_json('../data/movies_data.json', orient='split')\n",
    "        start = time.time()\n",
    "\n",
    "        model_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "        model_knn.fit(self.docs_topics)\n",
    "\n",
    "        movie_topics = self.get_movie_topics(movie_id)\n",
    "\n",
    "        if movie_topics is None:\n",
    "            return None\n",
    "\n",
    "        distances, indices = model_knn.kneighbors(movie_topics, n_neighbors=self.num_of_recommendation + 1)\n",
    "        similarities = 1 - distances.flatten()\n",
    "        similarities = similarities[1:]\n",
    "        indices = indices.flatten()\n",
    "        indices = indices[1:]\n",
    "\n",
    "        end = time.time()\n",
    "        print(f'Recommended in: {end - start} s')\n",
    "        return [{\n",
    "            'id': PandasHelper.get_id_from_series(self.docs_topics.iloc[[indices[index]]]),\n",
    "            'name': data[data['id'] == PandasHelper.get_id_from_series(self.docs_topics.iloc[[indices[index]]])].title.iloc[0],\n",
    "            'similarity': float(line)\n",
    "        } for index, line in enumerate(similarities)]\n",
    "\n",
    "    def get_movie_topics(self, movie_id):\n",
    "        movie_row = self.docs_topics[self.docs_topics.index == movie_id]\n",
    "\n",
    "        if movie_row.empty:\n",
    "            return None\n",
    "\n",
    "        row_values = movie_row.values.reshape(1, -1)\n",
    "\n",
    "        return row_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = Recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.recommend(480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
